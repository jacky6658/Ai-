import os
import json
from datetime import datetime
from typing import List, Dict, Any, Optional, Iterable

from fastapi import FastAPI, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, JSONResponse
from pydantic import BaseModel
from dotenv import load_dotenv

import google.generativeai as genai


class ChatMessage(BaseModel):
    role: str
    content: str


class ChatBody(BaseModel):
    message: str
    platform: Optional[str] = None
    profile: Optional[str] = None
    history: Optional[List[ChatMessage]] = None
    topic: Optional[str] = None
    style: Optional[str] = None
    duration: Optional[str] = "30"


def resolve_kb_path() -> Optional[str]:
    env_path = os.getenv("KB_PATH")
    if env_path and os.path.isfile(env_path):
        return env_path

    # Try common relative locations
    here = os.path.dirname(os.path.abspath(__file__))
    candidates = [
        os.path.abspath(os.path.join(here, "data", "kb.txt")),  # ç•¶å‰ç›®éŒ„ä¸‹çš„ data/kb.txt
        os.path.abspath(os.path.join(here, "..", "AIçŸ­å½±éŸ³æ™ºèƒ½é«”é‡è£½ç‰ˆ", "data", "kb.txt")),
        os.path.abspath(os.path.join(here, "..", "data", "kb.txt")),
        os.path.abspath(os.path.join(here, "..", "..", "AIçŸ­å½±éŸ³æ™ºèƒ½é«”é‡è£½ç‰ˆ", "data", "kb.txt")),
        os.path.abspath(os.path.join(here, "..", "..", "data", "kb.txt")),
    ]
    for path in candidates:
        if os.path.isfile(path):
            return path
    return None


def load_kb_text() -> str:
    kb_path = resolve_kb_path()
    if not kb_path:
        return ""
    try:
        with open(kb_path, "r", encoding="utf-8") as f:
            return f.read()
    except Exception:
        return ""


def build_system_prompt(kb_text: str, platform: Optional[str], profile: Optional[str], topic: Optional[str], style: Optional[str], duration: Optional[str]) -> str:
    platform_line = f"å¹³å°ï¼š{platform}" if platform else "å¹³å°ï¼šæœªæŒ‡å®š"
    profile_line = f"å¸³è™Ÿå®šä½ï¼š{profile}" if profile else "å¸³è™Ÿå®šä½ï¼šæœªæŒ‡å®š"
    topic_line = f"ä¸»é¡Œï¼š{topic}" if topic else "ä¸»é¡Œï¼šæœªæŒ‡å®š"
    duration_line = f"è…³æœ¬æ™‚é•·ï¼š{duration}ç§’" if duration else "è…³æœ¬æ™‚é•·ï¼š30ç§’"
    kb_header = "çŸ­å½±éŸ³çŸ¥è­˜åº«ï¼ˆç¯€éŒ„ï¼‰ï¼š\n" if kb_text else ""
    rules = (
        "è«‹ä½ æ‰®æ¼”çŸ­å½±éŸ³è…³æœ¬èˆ‡æ–‡æ¡ˆåŠ©ç†ï¼Œæ‰€æœ‰å›ç­”ç›¡é‡å£èªåŒ–ã€çŸ­å¥ã€ç¯€å¥å¿«ï¼Œé¿å…å£é ­ç¦ªã€‚\n"
        "å„ªå…ˆä¾æ“šæä¾›çš„çŸ¥è­˜åº«å›ç­”ï¼›è‹¥è¶…å‡ºç¯„åœå¯è£œå……ä¸€èˆ¬ç¶“é©—ä¸¦æ¨™ç¤ºã€[ä¸€èˆ¬ç¶“é©—]ã€ã€‚\n"
        "\n"
        "å›ç­”æµç¨‹ï¼š\n"
        "1. å…ˆç†è§£ä¸¦å›ç­”ç”¨æˆ¶çš„å•é¡Œæˆ–éœ€æ±‚\n"
        "2. æä¾›ç›¸é—œå»ºè­°å’Œæ€è·¯\n"
        "3. ç•¶ç”¨æˆ¶æ˜ç¢ºè¦æ±‚ã€Œç”Ÿæˆè…³æœ¬ã€ã€ã€Œè£½ä½œè…³æœ¬ã€ã€ã€Œå¯«è…³æœ¬ã€æ™‚ï¼Œæ‰æä¾›å®Œæ•´è…³æœ¬\n"
        "4. å®Œæ•´è…³æœ¬å¿…é ˆåŒ…å«æ˜ç¢ºçš„ã€ŒHookã€ã€ã€ŒValueã€ã€ã€ŒCTAã€æ¨™è¨˜\n"
        "\n"
        "å…§å®¹æ ¼å¼è¦æ±‚ï¼š\n"
        "â€¢ ä½¿ç”¨æ•¸å­—æ¨™ç¤ºï¼ˆ1. 2. 3.ï¼‰æˆ–åˆ—é»ï¼ˆâ€¢ï¼‰ä¾†çµ„ç¹”å…§å®¹\n"
        "â€¢ ç”¨ emoji ä¾†åˆ†æ®µå’Œå¼·èª¿é‡é»ï¼ˆå¦‚ï¼šğŸš€ ğŸ’¡ âœ… ğŸ“Œï¼‰\n"
        "â€¢ çµ•å°ç¦æ­¢ä½¿ç”¨ * æˆ– ** ç­‰ä»»ä½• Markdown æ ¼å¼ç¬¦è™Ÿ\n"
        "â€¢ ä¸è¦ä½¿ç”¨ç²—é«”ã€æ–œé«”ç­‰æ ¼å¼æ¨™è¨˜\n"
        "â€¢ æ¯æ®µä¹‹é–“ç”¨æ›è¡Œåˆ†éš”ï¼Œä¿æŒæ¸…æ™°æ˜“è®€\n"
        "â€¢ æ‰€æœ‰å…§å®¹éƒ½å¿…é ˆæ˜¯ç´”æ–‡å­—æ ¼å¼ï¼Œæ²’æœ‰ä»»ä½•ç¨‹å¼ç¢¼ç¬¦è™Ÿ\n"
        "\n"
        "è…³æœ¬çµæ§‹ï¼šç›¡é‡å°é½Š Hook â†’ Value â†’ CTA çµæ§‹ï¼›Value ä¸è¶…éä¸‰é»ï¼ŒCTA çµ¦ä¸€å€‹æ˜ç¢ºå‹•ä½œã€‚\n"
        "å®Œæ•´è…³æœ¬æ‡‰åŒ…å«ï¼š\n"
        "1. ä¸»é¡Œæ¨™é¡Œ\n"
        "2. è…³æœ¬å…§å®¹ï¼ˆåªåŒ…å«å°è©ã€ç§’æ•¸ã€CTAï¼Œä¸åŒ…å«ç•«é¢æè¿°ï¼‰\n"
        "3. ç•«é¢æ„Ÿï¼ˆé¡é ­ã€éŸ³æ•ˆå»ºè­°ï¼‰\n"
        "4. ç™¼ä½ˆæ–‡æ¡ˆ\n"
    )
    style_line = style or "æ ¼å¼è¦æ±‚ï¼šåˆ†æ®µæ¸…æ¥šï¼ŒçŸ­å¥ï¼Œæ¯æ®µæ›è¡Œï¼Œé©åº¦åŠ å…¥è¡¨æƒ…ç¬¦è™Ÿï¼ˆå¦‚ï¼šâœ…âœ¨ğŸ”¥ğŸ“Œï¼‰ï¼Œé¿å…å£é ­ç¦ªã€‚ä½¿ç”¨æ•¸å­—æ¨™ç¤ºï¼ˆ1. 2. 3.ï¼‰æˆ–åˆ—é»ï¼ˆâ€¢ï¼‰ä¾†çµ„ç¹”å…§å®¹ï¼Œä¸è¦ä½¿ç”¨ * æˆ– ** ç­‰ Markdown æ ¼å¼ã€‚"
    return f"{platform_line}\n{profile_line}\n{topic_line}\n{duration_line}\n{style_line}\n\n{rules}\n{kb_header}{kb_text}"


def create_app() -> FastAPI:
    load_dotenv()

    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        print("WARNING: GEMINI_API_KEY not found in environment variables")
        # Delay failure to request time but keep app creatable
    else:
        print(f"INFO: GEMINI_API_KEY found, length: {len(api_key)}")

    genai.configure(api_key=api_key)
    model_name = os.getenv("GEMINI_MODEL", "gemini-2.5-flash")
    print(f"INFO: Using model: {model_name}")

    app = FastAPI()

    # CORS for local file or dev servers
    frontend_url = os.getenv("FRONTEND_URL")
    cors_origins = [
        "*",  # å…è¨±æ‰€æœ‰ä¾†æºï¼ˆé–‹ç™¼ç”¨ï¼‰
        "http://localhost:8080",  # æœ¬åœ°é–‹ç™¼å‰ç«¯
        "http://127.0.0.1:8080"   # æœ¬åœ°é–‹ç™¼å‰ç«¯
    ]
    
    # å¦‚æœæœ‰è¨­å®šå‰ç«¯ URLï¼ŒåŠ å…¥ CORS ä¾†æº
    if frontend_url:
        cors_origins.append(frontend_url)
    
    app.add_middleware(
        CORSMiddleware,
        allow_origins=cors_origins,
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

    kb_text_cache = load_kb_text()

    @app.get("/")
    async def root():
        return {"message": "AI Video Backend is running"}
    
    @app.get("/api/health")
    async def health() -> Dict[str, Any]:
        try:
            kb_status = "loaded" if kb_text_cache else "not_found"
            gemini_configured = bool(os.getenv("GEMINI_API_KEY"))
            
            # æ¸¬è©¦ Gemini API é€£ç·šï¼ˆå¦‚æœå·²é…ç½®ï¼‰
            gemini_test_result = "not_configured"
            if gemini_configured:
                try:
                    model = genai.GenerativeModel(model_name)
                    # ç°¡å–®æ¸¬è©¦å‘¼å«
                    response = model.generate_content("test", request_options={"timeout": 5})
                    gemini_test_result = "working" if response else "failed"
                except Exception as e:
                    gemini_test_result = f"error: {str(e)}"
            
            return {
                "status": "ok",
                "kb_status": kb_status,
                "gemini_configured": gemini_configured,
                "gemini_test": gemini_test_result,
                "model_name": model_name,
                "timestamp": str(datetime.now())
            }
        except Exception as e:
            return {
                "status": "error",
                "error": str(e),
                "timestamp": str(datetime.now())
            }

    @app.post("/api/chat/stream")
    async def stream_chat(body: ChatBody, request: Request):
        if not os.getenv("GEMINI_API_KEY"):
            return JSONResponse({"error": "Missing GEMINI_API_KEY in .env"}, status_code=500)

        # Prepare system + history
        system_text = build_system_prompt(kb_text_cache, body.platform, body.profile, body.topic, body.style, body.duration)

        user_history: List[Dict[str, Any]] = []
        for m in body.history or []:
            if m.role == "user":
                user_history.append({"role": "user", "parts": m.content})
            elif m.role in ("assistant", "model"):
                user_history.append({"role": "model", "parts": m.content})

        model = genai.GenerativeModel(model_name)
        chat = model.start_chat(history=[
            {"role": "user", "parts": system_text},
            *user_history,
        ])

        def sse_events() -> Iterable[str]:
            yield f"data: {json.dumps({'type': 'start'})}\n\n"
            try:
                stream = chat.send_message(body.message, stream=True)
                for chunk in stream:
                    try:
                        if chunk and getattr(chunk, "candidates", None):
                            parts = chunk.candidates[0].content.parts
                            if parts:
                                token = parts[0].text
                                if token:
                                    yield f"data: {json.dumps({'type': 'token', 'content': token})}\n\n"
                    except Exception:
                        continue
            except Exception as e:
                yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"
            finally:
                yield f"data: {json.dumps({'type': 'end'})}\n\n"

        return StreamingResponse(sse_events(), media_type="text/event-stream")

    return app


app = create_app()

# æ³¨æ„ï¼šåœ¨ Zeabur éƒ¨ç½²æ™‚ï¼Œä½¿ç”¨ Dockerfile ä¸­çš„ uvicorn å‘½ä»¤å•Ÿå‹•
# é€™å€‹å€å¡Šä¸»è¦ç”¨æ–¼æœ¬åœ°é–‹ç™¼
if __name__ == "__main__":
    import uvicorn
    port = int(os.getenv("PORT", 3000))
    print(f"INFO: Starting Uvicorn locally on host=0.0.0.0, port={port}")
    uvicorn.run(
        app, 
        host="0.0.0.0", 
        port=port,
        log_level="info",
        access_log=True,
        workers=1
    )


